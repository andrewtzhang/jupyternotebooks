{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras as pl # TENSORFLOW w/ ROCm doesn't work w/ FX-8350 due to PCI-E 2.0\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\" \n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.convolutional import Conv3D, Deconv3D, Conv3DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "import dataproc\n",
    "import binvox_rw\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, 3, padding = 'same', input_shape=(32, 32, 32, 1), data_format=\"channels_last\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv3D(8, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator(phase_train=True, params={'z_size':200, 'strides':(2,2,2), 'kernel_size':(4,4,4)}):\n",
    "    \"\"\"\n",
    "    Returns a Generator Model with input params and phase_train \n",
    "    Args:\n",
    "        phase_train (boolean): training phase or not\n",
    "        params (dict): Dictionary with model parameters    \n",
    "    Returns:\n",
    "        model (keras.Model): Keras Generator model\n",
    "    \"\"\"\n",
    "    z_size = params['z_size']\n",
    "    strides = params['strides']\n",
    "    kernel_size = params['kernel_size']     \n",
    "    inputs = Input(shape=(1, 1, 1, z_size))\n",
    "    g1 = Deconv3D(filters=512, kernel_size=kernel_size,\n",
    "                  strides=(1, 1, 1), kernel_initializer='glorot_normal',\n",
    "                  bias_initializer='zeros', padding='valid')(inputs)\n",
    "    g1 = BatchNormalization()(g1, training=phase_train)\n",
    "    g1 = Activation(activation='relu')(g1)\n",
    "    g2 = Deconv3D(filters=256, kernel_size=kernel_size,\n",
    "                  strides=strides, kernel_initializer='glorot_normal',\n",
    "                  bias_initializer='zeros', padding='same')(g1)\n",
    "    g2 = BatchNormalization()(g2, training=phase_train)\n",
    "    g2 = Activation(activation='relu')(g2)\n",
    "    g3 = Deconv3D(filters=128, kernel_size=kernel_size,\n",
    "                  strides=strides, kernel_initializer='glorot_normal',\n",
    "                  bias_initializer='zeros', padding='same')(g2)\n",
    "    g3 = BatchNormalization()(g3, training=phase_train)\n",
    "    g3 = Activation(activation='relu')(g3)\n",
    "    g4 = Deconv3D(filters=64, kernel_size=kernel_size,\n",
    "                  strides=strides, kernel_initializer='glorot_normal',\n",
    "                  bias_initializer='zeros', padding='same')(g3)\n",
    "    g4 = BatchNormalization()(g4, training=phase_train)\n",
    "    g4 = Activation(activation='relu')(g4)\n",
    "    g5 = Deconv3D(filters=1, kernel_size=kernel_size,\n",
    "                  strides=strides, kernel_initializer='glorot_normal',\n",
    "                  bias_initializer='zeros', padding='same')(g4)\n",
    "    g5 = BatchNormalization()(g5, training=phase_train)\n",
    "    g5 = Activation(activation='sigmoid')(g5) \n",
    "    model = Model(inputs=inputs, outputs=g5)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-48b0d9e5d077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdisc_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'self'"
     ]
    }
   ],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = dataproc.data()\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    d = discriminator()\n",
    "    g = generator()\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            vox_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_vox = g.predict(noise, verbose=0)\n",
    "            #if index % 20 == 0:\n",
    "             #   image = combine_images(generated_images)\n",
    "              #  image = image*127.5+127.5\n",
    "               # Image.fromarray(image.astype(np.uint8)).save(\n",
    "                #    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((vox_batch, generated_vox))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "            d.trainable = False\n",
    "            g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "            d.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate(BATCH_SIZE, nice=False):\n",
    "def generate(BATCH_SIZE):\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    \"\"\"if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\"\"\"\n",
    "    noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "    generated_images = g.predict(noise, verbose=1)\n",
    "    image = combine_images(generated_images)\n",
    "    #Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")\n",
    "    image.write(generated.binvox)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
